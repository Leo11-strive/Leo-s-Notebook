# <center>数字时代人权的思考</center>
<center>李幸轩</center>

-----------------------------------
## 开篇
各位老师、同学们，下午好。

>  请大家和我一起，做一个短暂而深刻的思想实验。想象一下 1948 年的巴黎，在联合国大会的会场里，代表们手中郑重传递着一份文件，那份奠定我们现代文明基石的《世界人权宣言》。它的每一个字，都用古典的墨水小心翼翼地写在羊皮纸上，承载着人类在历经战火浩劫后，对尊严、自由与平等的，最沉重、最真诚的承诺。 

----------------------------------


>  现在，让我们瞬间回到 2025 年的今天。此刻，真正塑造我们视野、影响我们决策、甚至定义我们情感与欲望的，不再是博物馆里的羊皮纸条文，而是全球数据中心里，那几十亿、几百亿行冰冷而高效的代码所交织成的无形网络。 

>  所以，我想问一个或许有些冒犯，但对我们这一代人而言至关重要的问题：当法律的古典墨水，遇上了算法的现代电流时，我们今天在激烈辩护、在奋力争取的“人权”，和七十多年前那个诞生于战火与希望中的概念，还真的是同一个东西吗？ 

------------------------------------


>  提出这个问题，并非出于一种旁观者的哲学思辨。恰恰相反，这是我们，作为 ai，cs 专业的学生，一次无法回避的集体自省。因为我们非常清楚一个事实：我们不仅仅是这个数字世界的“原住民”，我们更是未来数字世界的“架构师”和“立法者”。我们写的每一行代码，设计的每一个算法，训练的每一个模型，都在为这个新世界的物理定律和社会规则奠基。 

>  因此，今天我们站在这里，探讨数字时代的人权，它不是一次置身事外的评述，而是一场来自代码世界未来从业者严肃的责任思考。 

----------------------------------------------

>  我们想分享的核心观点是：数字时代，并未从根本上颠覆人权关于尊严、自由、平等的核心精神，但它正在通过三种剧烈且深刻的方式，重塑人权实践的全新样态： 

>  * 第一，是权力主体的历史性转移。人权的主要防线，正从防范有形的“国家利维坦”，扩展到防范那些掌控着数据的、无形的“算法利维坦”。 

>  * 第二，是侵害方式的深度隐形。传统的物理强制和公开审查，正大规模地被我们不易察觉的算法规训、数据操控和认知塑造所取代。 

>  * 第三，是权利内涵的维度拓展。我们对隐私、言论、乃至生存发展权的理解，必须从线下的实体空间，紧急地延伸到我们日益沉浸的线上虚拟存在。 

>  所以，我们这代人的任务，绝不是在数字冲击的废墟上哀叹人权的过时，而是在这个全新的数字地基之上，用我们所学的技术语言和我们必须建立的伦理框架，对这部古老的人权法典，进行一次关键的“版本迭代”与“代码重构”。 

----------------------------------------

>  为了更系统地阐述这一过程，接下来，我的发言将围绕三个核心层次展开： 

>  * 首先，权力的“代码化”：我们将探讨，人权保护的对象如何从国家转向平台，算法如何成为一根看不见的权杖。 

>  * 其次，存在的“数字化”：我们将剖析，个体权利的内涵在数据的洪流中如何被侵蚀，又如何戏剧性地催生出新的权利形态。 

>  * 最后，也是最重要的，契约的“智能化”：我们将回归自身，思考作为未来技术的设计者，我们如何才能不负时代，去主动塑造一个更公正、更符合人类长远福祉的数字未来。 

----------------------------------------

## 第一层

>  好，让我们首先进入第一层剖析：权力的“代码化”——那根看不见的权杖与崛起的算法“利维坦”。 

>  在经典的人权理论中，我们最大的假想敌，是那个拥有绝对暴力机器的国家，也就是政治哲学家霍布斯笔下的“利维坦”。人权法典，就是公民为这个巨兽戴上的镣铐。 

>  然而今天，一个新的、甚至在某些维度上更强大的“利维坦”正在崛起。它不是由钢铁、军队和监狱构成，而是由服务器、数据流和我们亲手编写的代码构建而成。我们每天沉浸其中的巨型科技平台——GAFAM，它们早已超越了传统“公司”的范畴，演化为一种“准主权实体”。 

-------------------------------------

>  请想一想：它们制定规则，就是我们注册时从不阅读却必须点击“同意”的那上万字的《用户协议》，这本质上是它们的“宪法”；它们行使司法，就是内容审查、流量分配、乃至账号封禁的生杀大权，这是它们的“最高法院”；它们拥有数以十亿计的“数字国民”，这些国民的经济生活、社会交往甚至政治观点，都深刻地被其平台架构所塑造。 

>  哈佛大学教授肖莎娜·祖博夫在《监视资本主义时代》中精准地指出：这种新型权力的根基，是对我们每一个点击、每一次停留、每一段关系的无情开采，和对我们未来行为的精准预测。 


>  这对我们意味着什么？意味着我们亲手编写的每一行用户画像代码，我们为了提升 DAU（日活跃用户数）而设计的每一个 A/B 测试，我们训练的每一个用以预测用户偏好的模型，都可能在不经意间，为这座新型权力大厦添上了一块砖、一片瓦。 

>  如果说权力主体的转移是第一重冲击，那么治理模式的变革，则更加隐蔽和致命。 

>  现代法治的基石，是法律的公开、透明与程序正义。你被判决，你知道是依据哪条法律；你被拒绝，你知道是基于何种标准；你有权申辩，有权上诉。但在算法的“黑箱”治理面前，这一切正在被无情地悬置。 

>  想象一下这样的场景：你的求职简历，仅仅因为某个指标不在某个 AI 系统的“白名单”里，就被直接丢进了数字垃圾桶；你的贷款申请，因为你的消费数据触碰了某个信用模型的隐藏变量，就被秒级拒绝，且不给任何理由；甚至，有可能在司法实践中，法官所参照的那个用以评估再犯率的量刑建议系统，其内部逻辑对于被告、律师、甚至法官本人，都是一个无法窥探的秘密。 

>  数学家凯西·奥尼尔在《算法霸权》中，将这些不透明、不可辩驳且大规模应用的算法，精准地称为“数学杀伤性武器”。它们会因为训练数据中潜藏的人类历史偏见，而系统性地歧视特定性别、种族和阶层，制造出一种新型的、难以追责的、却又冰冷坚固的数字阶级。 

------------------------------------------

>  这就带来了数字时代人权的第一组核心拷问：当法律条文的确定性，被算法模型的概率性所取代时，我们如何捍卫“算法面前的平等权”? 当我们被一个我们无法理解的逻辑所审判和裁决时，我们又该如何去行使那项对于人之为人的尊严至关重要的——“要求解释的权利”？ 

>  这个问题，尤其需要我们这些“黑箱”的创造者，来给出答案。 

-----------------------------------------------

## 第二层
>  如果说权力的代码化，重塑了人与权力的外部关系，那么接下来我们要进入的第二层——存在的“数字化”，则将探针伸向了我们每个人的内部世界。它要追问的是：当我们的灵魂可以被量化，我们的核心权利，又在经历着怎样剧烈的侵蚀与演化？ 

*(论述一：隐私权)*

>  首先是隐私权。在工业时代，隐私权是美国大法官布兰迪斯口中“不受打扰的权利”，它是一道物理的墙，保护我们的家庭与信件。但在今天，这道墙早已布满数据传输的漏洞。我们甚至心甘情愿地，用海量的个人数据————我们的位置、偏好、健康状况————去交换算法带来的便捷、效率与个性化。这是一种我们每个人都参与其中的、心照不宣的“浮士德式交易”。 

>  正因如此，隐私的重心发生了根本性的漂移：它已经从被动的“防止被看”，演变为主动的“决定我的数据如何被看见、被理解、被利用、被预测”。这不再仅仅是防御，而是一种关乎主体性的“数据自决权”。欧洲的《通用数据保护条例》之所以在全球引起如此大的震动，正是因为它首次将“被遗忘权”和“数据可携权”这些主动权利法典化。这标志着我们对隐私权的理解，正式从 1.0 时代，艰难地迈向了 2.0 时代。 

*(论述二：思想与表达自由)*

>  其次，我们再来看思想与表达自由，这或许是数字时代最吊诡的一个悖论。 

>  一方面，互联网无疑创造了人类历史上最广阔的“雅典广场”。从“阿拉伯之春”到“ #MeToo ”运动，无数曾经被压抑、被边缘化的声音，借由技术获得了前所未有的赋权，这是它光辉的一面。 

>  但另一方面，当我们以为自己在信息的海洋中自由冲浪和呐喊时，算法正在为我们每个人，精心建造一座座无比舒适、却又坚不可摧的“回音室监狱”。推荐引擎通过精准的“信息投喂”，让我们只看得见我们想看的观点，只听得到我们早已认同的声音。异见被技术性地过滤，社会共识被算法撕裂并导向极化。 

>  这是一种比直接删除言论更高级、更隐蔽的审查——它不是让你闭嘴，而是通过重塑你的信息环境，让不同的声音在你面前，彻底消失。 

>  这就引出了一个极具前瞻性的问题：当我们的注意力、观点、甚至欲望都可以被算法设计和操控时，我们是否需要主张一种更新的、更根本的权利————不妨叫它“认知自由权“？一种确保我们的大脑和心智，免于被他者进行非法入侵、污染和塑造的终极权利？ 

*(论述三：发展权)*

>  最后，我们必须关注到发展权。这项旨在消除不平等、保障每个人都能平等分享社会进步成果的权利，在数字时代同样面临着新的鸿沟。 

>  过去的文盲，是不识字。而今天的“数字文盲”，是那些无法理解代码的基本逻辑、无法辨别数据的真实性、无法与智能系统进行批判性互动的人。数字鸿沟，早已不只是“家里有没有一根网线”的接入鸿沟，它更是“会不会有效使用”的技能鸿沟，和“懂不懂其背后所以然”的认知鸿沟。这条鸿沟，正在无声地固化，甚至加剧着现实世界中的社会不平等。 

>  因此，今天我们谈论发展权，就必须把“平等的数字接入权”，和更重要的，“普惠的 AI 素养与算法思维教育权”包含在内。因为这，才是通往未来世界的真正入场券。 

-----------------------------------------


## 第三层
>  那么，朋友们，面对如此宏大而深刻的结构性变迁，我们难道只能束手无策，成为被技术浪潮裹挟的“代码工人”吗？ 

>  **绝不。** 

>  这就引出了我们今天想要探讨的第三层，也是我们认为的破局点：契约的“智能化”——作为构建者的我们，路在何方？ 



>  二十多年前，哈佛法学院的劳伦斯·莱斯格教授就提出了一个至今依然振聋发聩的论断：“代码即法律”（Code is Law）。他的意思是，在网络空间里，真正决定我们能做什么、不能做什么的，并非遥远的法律条文，而是我们亲手编写的底层代码和架构。是代码，在以最高效、最强制的方式，为数字世界“立法”。 

>  今天，我们必须首先勇敢地承认并拥抱这个“权力”。不是在服务于某个产品，我们是在塑造一个社会；我们不是在优化一个参数，我们是在调整公共生活的准则。 

-----------------------------------------

>  而我们今天想说的，正是基于这一判断的下一步演进：我们必须推动社会，更必须推动我们自己，实现从“代码即法律”到“伦理融入代码”的伟大转变。

>  这不是一句空洞的口号，而是一份清晰的行动纲领。它包含三个层面： 



**第一：重塑技术哲学，将“人权优先设计”作为行业金标准。**

>  这意味着，隐私保护、算法公平、信息透明、决策可解释性，这些绝不能再是产品上线后，为了应对舆论危机或法律诉讼才匆忙打上的“伦理补丁”。它们必须成为系统设计的初始默认值，成为我们写下第一行代码时，就内嵌于 DNA 中的核心原则。我相信这在任何领域都是共通的，这对我们在座的每一位同学都提出了一个更高的要求：我们不仅要在自身行业卓越，我们更要做一个伦理上清醒的思考者。 

**第二：建立新型的责任框架，推动“算法审计”与“多方共治”。** 

> 单靠工程师的道德自觉是远远不够的。我们需要建立独立的、受信任的第三方机构，来对涉及重大公共利益（如金融、司法、医疗）的算法模型，进行定期的、专业的技术与伦理审计，就像上市公司需要财务审计一样。同时，我们必须打破平台单边制定规则的“独裁”模式，倡导政府、企业、我们技术社群、以及广大公众，共同参与到数字世界核心规则的制定中来。 

**第三：自觉承担教育责任，致力于提升“全民数字素养”，培养批判性的使用者。 **

>  一个健康的数字社会，不仅需要负责任的构建者，更需要被赋权的、清醒的使用者。我们作为最懂技术的一群人，有责任通过知识普及、开源工具和公共教育，帮助公众理解算法的基本逻辑，识别无处不在的数据偏见与信息操纵，让他们从被动的“数据矿工”，成长为自身数字权利的积极捍卫者。 

-----------------------------------------

同学们，


>  权力的“代码化”，让无形的平台成为新的巨兽，对我们的权利边界进行着持续的压力测试； 

>  存在的“数字化”，让我们的隐私、思想乃至生存发展的基本权利，其内涵与外延都被深刻地重塑与再定义； 

>  真正通往契约“智能化”的未来之路，那就是将伦理与人权，深深地嵌入我们作为构建者的技术哲学与日常实践之中，实现从“代码即法律”到“伦理融入代码”的转变。 

>  这一切的论述，都指向我们最初的核心观点：人权的内核精神恒久不变，但它的实践范式，它的应用场景，它的保护契约，必须在我们这一代人的手中，完成一次从原子世界到比特世界的，关键的、彻底的“代码重构”。 

## 总结
>  上世纪中叶，当计算机科学的曙光刚刚降临时，控制论的伟大奠基人诺伯特·维纳，就曾向世界发出过一个先知般的警告，他说： 

>  “我们最好对这部我们亲手创造的机器，它真正想要达成的目的是什么，做到心中有数。因为，机器很可能会忠实地得到它。” 


>  今天，我们，在座的每一位，就是正站在维纳所说的那个历史节点上的人。我们，就是正在向这部名为“数字时代”的超级机器，输入初始目的、写入核心指令的第一代工程师、科学家和思想者。 

>  历史，给了我们这一代人一支前所未有的、可以直接构建社会运行规则的笔。因此，问题不再是我们是否会书写未来，而是我们将书写一个怎样的未来。

>  我们一起做出选择：不作只问实现不问对错的价值虚无主义者，也不作盲目崇拜技术的乐观主义者，而是努力成为一个人文精神与科学精神兼备的、负责任的数字世界‘架构师’。为一个人人都能享有尊严、自由与平等的数字未来，写下属于我们这一代人的，最坚实、最温暖的代码。

>  我的发言到此结束，谢谢大家。