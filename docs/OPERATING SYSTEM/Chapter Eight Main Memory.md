* Memory is much slower than processors, and consumes more energy

![[image-776.png]]

![[image-779.png]]

* 为什么说 CPU 只能直接访问 cpu 和 main memory，为什么不说 cpu 还可以直接访问 cache？
> 因为这里的“**能直接访问**”这几个字，指的不是“物理距离近不近”，而是 **在体系结构（ISA）这个层面上，CPU 把谁当成“有独立地址、能被指令显式操作的对象”**。

> Cache 更像是一个在中间偷偷帮忙的“加速器”，而不是一个“你可以点名访问的地方”。


* 程序在运行之中，是储存在硬盘里的
* 写完一个程序之后，大概有三个阶段
> 编译，目标文件，链接，形成完整的可执行文件
> one or more objects generated by a compiler and combines them into a single executable program.
* Symbolic Address: Addresses in the source program are generally symbolic (such as the variable count). 程序中存在的地址
* Relocatable Addresses（可重定位地址）: A compiler typically binds these symbolic addresses to relocatable addresses (such as “14 bytes from the beginning of this module”). 通过可重定位地址，去访问真正的地址
* Absolute Addresses（绝对地址）: The linker or loader binds the relocatable addresses to absolute addresses (such as 74014).


## Binding of instructions and Data to Memory
* **Compile time**（编译时刻）:  If memory location known a priori, **absolute code** can be generated; must recompile code if starting location changes
* **Load time**（装入时刻）:  Must generate **relocatable code** if memory location is not known at compile time
* **Execution time**（执行时刻）:  Binding delayed until run time if the process can be moved during its execution from one memory segment to another.  Need hardware support for address maps (e.g., base and limit registers)
* A pair of **base** and **limit** registers define the logical address space
![[image-780.png]]
* The concept of a logical address space that is bound to a separate **physical address space** is central to proper memory management
* **Logical address** – generated by the CPU; also referred to as **virtual address**
* **Logical** and **physical** addresses are the same in compile-time and load-time address-binding schemes;
![[image-781.png]]
* **Logical** (virtual) and **physical** addresses differ in execution-time address-binding scheme
![[image-782.png]]

![[image-783.png]]

![[image-784.png]]

## MMU

![[image-785.png]]

![[image-786.png]]
* 动态 loading
* 动态连接
> 连接步骤推迟到程序运行时连接
> Small piece of code, _stub_, used to locate the appropriate memory-resident library routine
* 封装与复用
* Dynamic linking and shared libraries generally **require help** from the operating system.
* 共享库
* Dynamically linked libraries (DLLs) are system libraries that are linked to user programs when the programs are run, also known as **shared libraries**
* 动态连接：地址的映射会比较复杂，时间也会有耗费
* 安全性问题，如果库函数出现问题，所有使用这个库函数的程序都会出现问题
![[image-860.png]]

![[image-861.png]]

* Relocation register contains value of smallest _physical_ address: 开始地址
* Limit register contains range of _logical_ addresses – each logical address must be less than the limit register
* 通过硬件保护内存
![[image-862.png]]
* 上述是硬件实现
> 为什么不通过软件来实现？

![[image-864.png]]

![[image-865.png]]

![[image-866.png]]

* 对于操作系统来说，操作系统的代码可以访问内存中的任何地方的

## **Contiguous Allocation**
* 单一连续分配
> 用户区只允许调用一道程序运行
![[image-863.png]]

* 动态分区
> Hole – block of available memory; holes of various size are scattered throughout memory
> When a process arrives, it is allocated memory from a hole large enough to accommodate it
* Operating system maintains information about:  
    a) allocated partitions    b) free partitions (hole)
* how to satisfy a request of size n from a list of free holes
* First-fit (首次适应)
> Allocate the _first_ hole that is big enough.
* Next-fit
> 不会从头开始找，从之前那一个之后的空格再进行 fit
* Best fit
> Allocate the _smallest_ hole that is big enough; must search entire list, unless ordered by size
* worst fit
> 找到最大的那个
* First-fit and best-fit are better than worst-fit in terms of speed and storage utilization
* 快速适应算法：也称分类搜索算法，将空闲分区按客量大小进行分类，设置素引表项，每一个空闲分区类型对应一项，挂成链(把原来一根变成多根)
* 根据进程长度，从索引表项中找到能容纳他的最小空闲区链表；从链表中取下第一块进行分配。
* 伙伴系统：每个空闲分区大小必须是2的n次幂字节；对进程占用空间n计算一个i值使得2i>n，从剩余空闲分区找最适合的;若无则将分区逐层拆分;释放时则逐层合并
* 伙伴系统：每个空闲分区大小必须是2的n次幂字节；对进程占用空间n计算一个i值使得2i>n，从剩余空闲分区找最适合的;若无则将分区逐层拆分;释放时则逐层合并

## Fragmentation

![[image-867.png]]

* Reduce external fragmentation by  **compaction/defragmentation**
* Shuffle memory contents to place all free memory together in one large block, e.g., move all processes toward one end of memory, all holes move in the other direction (expensive)
* Compaction is possible _only_ if relocation is dynamic, and is done at execution time
![[image-868.png]]

## Paging
![[image-871.png]]
* 还是会有内部碎片
* frame 大小和 page 大小的匹配

## Address Translation Scheme
* 地址构成是：page offset；页号
![[image-872.png]]

## Paging hardware
![[image-873.png]]

![[image-874.png|124x146]]

## Address Translation
![[image-875.png]]
* 首先因为 4 kb，所以虚地址 offset 的位数就知道了

## Free Frames
* 存在很多空闲 frame，直接做个列表即可
![[image-876.png]]

* Page table
> 放置在内存中
* **Page-table base register (PTBR)** points to the page table
* **Page-table length register (PTLR)** indicates size of the page table
* In this scheme every data/instruction access requires two memory accesses.  One for the page table and one for the data/instruction.
> 需要两次的内存访问
* TLB
> The two-memory-access problem can be solved by the use of a special fast-lookup hardware cache called **associative memory** or **translation look-aside buffers (TLBs** 转换旁视缓冲**,** 一称快表**)**
* 可以实现并行
* Some TLBs store **address-space identifiers (ASIDs)** in each TLB entry – uniquely identifies each process to provide address-space protection for that process
* 为什么并行？
> 硬件实现，利用 cache
![[image-877.png]]

## **Effective Access Time**
![[image-878.png]]

* Memory protection implemented by associating protection bit with each frame
* **Valid-invalid** bit attached to each entry in the page table:
> “valid” indicates that the associated page is in the process’ logical address space, and is thus a legal page
> “invalid” indicates that the page is not in the process’ logical address space

![[image-879.png]]

## Shared Pages
* 每个进程都有自己的 page table，限制内存空间的访问
* 如何共享？
![[image-880.png]]
* 三个进程，ed 1，ed 2，ed 3 如果要共享内存的话，只要把它们的 page table 的对应的 frame 一致即可
* Shared code must appear in same location in the logical address space of all processes
> 必须相同的逻辑地址，但是真的一定要一样吗？其实是不是可以不一样的
* One copy of read-only (reentrant) code shared among processes (i.e., text editors, compilers, window systems).

## Structure of the Page Table
* Hierarchical Paging
> Break up the logical address space into multiple page tables – to _page_ the page table
* Break up the logical address space into multiple page tables – to _page_ the page table
![[image-881.png]]

* 多级页表
![[image-882.png]]
* **Page-table base register (PTBR)**
![[image-883.png]]

![[image-884.png]]

* Hashed Page Tables
> Common in address spaces > 32 bits
![[image-885.png]]

![[image-886.png]]

* Inverted Page Table
> One entry for each real page of memory
![[image-887.png]]
![[image-889.png]]
![[image-890.png]]

![[image-888.png]]


## Swapping
* A process can be swapped temporarily out of memory to a backing store, and then brought back into memory for continued execution
* **Backing store** – fast disk large enough to accommodate copies of all memory images for all users; must provide direct access to these memory images
* **Roll out, roll in** – swapping variant used for _priority-based_ scheduling algorithms; lower-priority process is swapped out so higher-priority process can be loaded and executed


## Segmentation
* Memory-management scheme that supports user view of memory
![[image-891.png]]

![[image-892.png]]

![[image-893.png]]

* Logical address consists of a two tuple:
> <segment-number, offset>
* **Segment table** – maps two-dimensional physical addresses; each table entry has:
![[image-894.png]]
* **Segment-table base register (STBR)** points to the segment table’s location in memory*
* **Segment-table length register (STLR)** indicates number of segments used by a program;
